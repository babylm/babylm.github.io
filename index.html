<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="stylesheet.css">
  <meta name="google-site-verification" content="uGXw8B5MkU92VZio-qMGqDxvDPk9t5WuvJPCuMmwuA8"/>
  <link rel="icon" href="./images/pacifier.png">
</head>

<body>


<div style="display:inline">
 <img style="float: left; padding-right: 20px;" src="./images/pacifier.png" height="80"> 
 <div class="master-title"> <b>Baby</b>LM Challenge </div> 
 <div class="subheader"> Sample-efficient pretraining on a developmentally plausible corpus </div> 
</div>


<div id="navbar">
<h4> <a href="index.html"> Overview </a> • <a href="guidelines.html"> Guidelines </a> • <a href="timeline.html"> Timeline</a> • <a href="faqs.html"> FAQs </a> <hr> </h4> 
</div>

<div class="greybox">

<div class="paragraph"> <b> Summary: </b> The 3rd BabyLM Challenge will be held as a workshop for EMNLP 2025! The overarching goals of the challenge remain the same, however, some of the rules are different for this year. See below for an overview of rules updates. </div>

<div class="bullet"> • All data is available <a href="https://osf.io/ad7qg/"><u>at this OSF directory!</u></a> Data includes:</div> 

<div class="bullet"> &#8594; A 100M and 10M word text-only dataset, with higher proportion child and child-directed speech.</a></div>

<div class="bullet"> &#8594; A <b> multimodal dataset </b> with 50M words of paired text-image data, and 50M words text-only data. </div>

<!-- <div class="bullet"> • The evaluation pipeline is out <a href="https://github.com/babylm/evaluation-pipeline-2024">here</a>! </div> -->
<div class="paragraph"> <b> New track: Interactivity </b> The INTERACTION track debuts this year to allow for interaction between multiple agents during training.</div>
  
<div class="paragraph"> See the <a href="guidelines.html">guidelines</a> for an overview of submission tracks and pretraining data. See the <a href="https://arxiv.org/pdf/2502.10645">updated call for papers</a> for a detailed description of the task setup and data. </div>

<div class="paragraph"> Consider <a href="https://join.slack.com/t/babylmchallenge/shared_invite/zt-2gqgqaumu-5ebxxADuT561aT_ooKbT1Q">joining the BabyLM Slack</a> if you have any questions for the organizers or want to connect with other participants!</div>

</div>

<!-- <div class="title"> Submission guide </div> <br>
  Submit <a href="https://openreview.net/group?id=EMNLP/2024/Workshop/CoNLL_Shared_Task/BabyLM_Challenge">Here</a>
  <p>To fill out the submission, please prepare these two things:</p>
<ol>
<li>A HuggingFace link to your models.</li>
<li>A download link to your results, assembled via the collect_results.py script in babylm/evaluation-pipeline-2024.</li>
</ol>
  Paper submission follows CoNLL template with 4-8 pages, as well as a hyperparameter <a href="https://forms.gle/nRjdt5w5rCoFFqnJ6"> form </a>. -->
<div class="title"> Rules Updates for BabyLM Round 3 </div> <br>

<div class="bullet"> • We introduce a new Interaction track,</b> exploring how feedback and interaction can assist with sample-efficient language modeling. This track will allow pre-trained language models to serve as teacher models; however, student models are still required to train on 100 million words or less. </a></div>

<div class="bullet"> • Last year, we encouraged multi-modal submissions, <b> by introducing a vision-language track. We continue the track this year. </b> For both text-only and multimodal tracks, participants are free to construct their own datasets, provided that they stay within the 100M or 10M word budget.</a></div>

<div class="bullet"> • To encourage contributions that are related to the goals of the challenge but do not involve direct competition entries, <b> we allow submissions to the workshop.</b> This could include things like novel cognitively-inspired evaluation metrics or in-depth analyses of one particular BabyLM model. </a></div>

<div class="bullet"> • This year, we will impose additional compute limitations on all challenge tracks.
Models may not conduct more than 10 epochs over their training data. See the call for papers for more details. </a></div>
</div>



<div class="title"> Overview </div> <br>
  
    <img style="float: right; padding-left: 20px; padding-bottom: 15px;" src="./images/model_sizes.png" height="160"> 

<div class="paragraph"> Huge effort has been put into optimizing LM pretraining at massive scales in the last several years. While growing parameter counts often get the most attention, datasets have also grown by orders of magnitude. For example, <a href="https://arxiv.org/abs/2203.15556v1"> Chinchilla </a> sees 1.4 <b>trillion</b> words during training---well over 10000 words for every one word a 13 year old child has heard in their entire life.</div>

<div class="paragraph"> The goal of this workshop is to incentivize researchers with an interest in pretraining or cognitive modeling to focus their efforts on optimizing pretraining given data limitations inspired by human development. Additionally, we hope to democratize research on pretraining—which is typically thought to be practical only for large industry groups—by drawing attention to open problems that can be addressed on a university budget. </div>

<div class="title" > Why <100 Million Words? </div>
  
<div class="paragraph"> Focusing on scaled-down pretraining has several potential benefits: <br> First, small-scale pretraining can be a sandbox for developing novel techniques for improving data efficiency. These techniques have the potential to then scale up to larger scales commonly seen in applied NLP or used to enhance current approaches to modeling low-resource languages. Second, improving our ability to train LMs on the same kinds and quantities of data that humans learn from hopefully will give us greater access to plausible cognitive models of humans and help us understand what allows humans to acquire language so efficiently. </div>

<div class="title"> Organization Team </div>
<div class = "people">
<div class="bullet">• Lucas Charpentier (LTG, University of Oslo) </div> 
<div class="bullet">• Leshem Choshen (IBM Research, MIT) </div> 
<div class="bullet">• Ryan Cotterell (ETH Zurich) </div> 
<div class="bullet">• Mustafa Omer Gul (Cornell University) </div> 
<div class="bullet">• Michael Hu (NYU) </div> 
<div class="bullet">• Jing Liu (ENS-PSL) </div> 
<div class="bullet">• Jaap Jumelet (University of Groningen) </div> 
<div class="bullet">• Tal Linzen (NYU) </div>
<div class="bullet">• Aaron Mueller (Northeastern) </div> 
<div class="bullet">• Candace Ross (Meta AI) </div> 
<div class="bullet">• Raj Sanjay Shah (Georgia Institute of Technology) </div> 
<div class="bullet">• Alex Warstadt (UCSD) </div> 
<div class="bullet">• Ethan Wilcox (Georgetown) </div> 
<div class="bullet">• Adina Williams (Meta AI) </div> 
</div>

<br>
The BabyLM Challenge was held in 2023 and 2024 as a shared task. At the following link, you can find the <a href="https://arxiv.org/abs/2404.06214"> last year's call for papers </a>  </a>.


</div>

<div class="footer">

<div style="float:right;"> Images provided by Smashicons </div>

</div>

</body>



