<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="stylesheet.css">
</head>

<body>

<!-- <div style="float: right; padding: 30px; font-size: 12px;"> <img src="images/baby-nn.jpg" height="330"> <br>
"Baby vs. Neural Net Language" from <a href="https://stablediffusionweb.com/#demo"> Stable Diffusion </a> </div> -->


<div style="display:inline">
 <img style="float: left; padding-right: 20px;" src="./images/pacifier.png" height="80"> 
 <div class="master-title"> <b>Baby</b>LM Challenge </div> 
 <div class="subheader"> Sample-efficient pretraining on a developmentally plausible corpus </div> 
</div>

<div id="navbar">
<h4> <a href="index.html"> Overview </a> • <a href="guidelines.html"> Guidelines </a> • <a href="timeline.html"> Timeline</a> • <a href="faqs.html"> FAQs </a> <hr> </h4> 
</div>

<div class="paragraph"> Submissions should be implimented in Huggingface's Transformers library and can be submitted along one of three submission tracks. The data has been released and can be downloaded <a href="https://github.com/babylm/babylm.github.io/raw/main/babylm_data.zip"; download="download">here</a>. </div>

<div class="title"> Submission Tracks </div>

<div class="paragraph"> We will evaluate models in three cateogries: <b> strict </b>, <b> strict-small </b> and <b> loose </b>. </div>

<div class="bullet"> <b> • Strict </b> and <b> Strict-Small: </b> The strict and strict-small tracks require that submissions are trained exclusively on a fixed dataset. The only difference between these tracks is the size of the dataset (~10M words vs. ~100M words). Winners will be determined based on performance on a shared evaluation set consisting of syntactic evaluation and NLU tasks. </div>

<div class="bullet"> <b> • Loose: </b> Submissions are still limited to ~100M words or less of training data, and will be tested on the shared evaluation set. However, they are permitted to use unlimited non-linguistic data. Additionally, training on additional text is allowed without limits if that text is generated by a model trained following the above restrictions. Winners will be selected holistically based on evaluation performance, relevance to the shared task goals, potential impact, and originality. </div>





<div class="title"> Pretraining Data </div>

<div class="paragraph"> We distribute a developmentally plausible pretraining dataset inspired by the input to children. Submissions must use only this training data to be considered for the strict and strict-small tracks, but may use alternate or additional data for other tracks. The dataset has the following properties: </div>


<div class="bullet"><b> • Under 100M words: </b> Children are exposed to 2M-7M words per year <a href="https://pubs.asha.org/doi/10.1044/2016_AJSLP-15-0169"> (Gilkerson et al., 2017) </a>. Choosing the beginning of adolescence (age 13) as a cutoff, children are exposed to at maximum 91M words, which we round up to 100M. </div>

<div class="bullet"> <b> • Mostly transcribed speech: </b> Most of the input to children is spoken; thus, our dataset focuses on transcribed speech. </div>

<div class="bullet"> <b> • Mixed domain, consisting of the following sources: </b> CHILDES (child-directed speech), OpenSubtitles (speech), BNC (speech), TED talks (speech), children's books (simple written language). </div>

<div class="paragraph"> See the <a href="https://arxiv.org/abs/2301.11796">call for papers</a> for a detailed breakdown of the pretraining datasets.</div>


<div class="title"> Evaluation Pipeline </div>

<div class="paragraph"> Models will be evaluated on a shared pipeline, which will be released in March 2023. </div>

</div>


<div class="footer">
<div style="float:right;"> Images provided by Smashicons </div>
</div>

</body>



