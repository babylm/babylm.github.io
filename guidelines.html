<!DOCTYPE html>
<html>
<head>
  <link rel="stylesheet" href="stylesheet.css">
</head>

<body>

<!-- <div style="float: right; padding: 30px; font-size: 12px;"> <img src="images/baby-nn.jpg" height="330"> <br>
"Baby vs. Neural Net Language" from <a href="https://stablediffusionweb.com/#demo"> Stable Diffusion </a> </div> -->


<div style="display:inline">
 <img style="float: left; padding-right: 20px;" src="./images/pacifier.png" height="80"> 
 <div class="master-title"> <b>Baby</b>LM Challenge </div> 
 <div class="subheader"> Sample-efficient pretraining on a developmentally plausible corpus </div> 
</div>

<div id="navbar">
<h4> <a href="index.html"> Overview </a> • <a href="guidelines.html"> Guidelines </a> • <a href="timeline.html"> Timeline</a> <hr> </h4> 
</div>

<div class="paragraph"> Submissions should be implimented in Huggingface's Transformers library and can be submitted along one of three submission tracks. Data will be released in early 2023. </div>



<div class="title"> Submission Tracks </div>

<div class="paragraph"> We will evaluate models in three cateogries: <b> strict </b>, <b> strict-small </b> and <b> loose </b> </div>

<div class="bullet"> <b> • Strict </b> and <b> Strict-Small: </b> The strict and strict-small tracks require that submissions are trained exclusively on a fixed dataset. The only difference between these tracks is the size of the dataset (~10M words vs. ~60M words). Winners will be determined based on performance on the shared evaluation set. </div>

<div class="bullet"> <b> • Loose: </b> Submissions are still limited to ~100M words or less of training data, and will be tested on the shared evaluation set. However, they are permitted to use unlimited non-linguistic data. Additionally, training on additional text is allowed without limits if that text is generated by a model trained following the above restrictions. Winners will be selected holistically based on evaluation performance, relevance to the shared task goals, potential impact, and originality. </div>





<div class="title"> Pretraining Data </div>

<div class="paragraph"> We will distribute a developmentally plausible pretraining dataset inspired by the input to children. Submissions must use only this training data to be considered for the strict track, but may use alternate or additional data for other tracks. The dataset will have the following properties: </div>


<div class="bullet"><b> • Under 100M words: </b> Children are exposed to 2M-7M words per year <a href="https://pubs.asha.org/doi/10.1044/2016_AJSLP-15-0169"> (Gilkerson et al., 2017) </a>. Choosing the beginning of adolescence (age 13) as a cutoff, children are exposed to at maximum 91M words, which we round up to 100M. </div>

<div class="bullet"> <b> • Mostly transcribed speech: </b> Most of the input to children is spoken, thus our dataset will focus on transcribed speech. </div>

<div class="bullet"> <b> • Mixed domain, consisting of (some of) the following sources: </b> CHILDES (child directed speech), OpenSubtitles (speech), COCA (speech), BNC (speech), TED talks (speech), Newsela (simplified text) </div>




<div class="title"> Evaluation Pipeline </div>

<div class="paragraph"> Models will be evaluated on a shared pipeline, which will be released in early 2023. </div>

</div>


<div class="footer">
<div style="float:right;"> Images provided by Smashicons </div>
</div>

</body>



